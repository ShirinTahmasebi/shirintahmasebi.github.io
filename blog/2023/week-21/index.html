<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review - Week 21 | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Top NLP Papers Published from May 22 to May 28 "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/blog/2023/week-21/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/background/">Background </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review - Week 21</h1> <p class="post-meta"> May 28, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/papers"> <i class="fa-solid fa-tag fa-sm"></i> papers</a>   <a href="/blog/category/weekly-review"> <i class="fa-solid fa-tag fa-sm"></i> weekly-review</a>   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#selfinstruct-aligning-language-models-with-self-generated-instructions">SelfInstruct: Aligning Language Models with Self-Generated Instructions</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>Here is the list of the most interesting papers published in this week:</p> <ul> <li>Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models</li> <li>Leveraging Large Language Models in Conversational Recommender Systems</li> <li><a href="/blog/2023/week-21/#selfinstruct-aligning-language-models-with-self-generated-instructions">SelfInstruct: Aligning Language Models with Self-Generated Instructions</a></li> </ul> <hr> <h2 id="selfinstruct-aligning-language-models-with-self-generated-instructions"><a href="https://arxiv.org/pdf/2212.10560.pdf" rel="external nofollow noopener" target="_blank">SelfInstruct: Aligning Language Models with Self-Generated Instructions</a></h2> <p>SelfInstruct focuses on the automatic generation of instruction instances for training language models to follow instructions effectively. The paper introduces a pipeline for generating instructions and associated input-output samples.</p> <p>Before we dive into the step-by-step details of the pipeline, let’s start by giving a broad overview of what this pipeline accomplishes overall. First of all, the dataset of instructions that is going to be generated and expanded in this work has three main attributes:</p> <ol> <li> <strong>Instruction:</strong> This is the natural language instruction that defines a specific task. It provides the context for the task that the language model needs to understand and follow.</li> <li> <strong>Input:</strong> This represents the input data or information required to perform the task described in the instruction. It can vary depending on the nature of the task and may include text, numbers, or other data.</li> <li> <strong>Output:</strong> This corresponds to the expected output or the desired result of the task.</li> </ol> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Example:

Instruction: Write a summary of the SELF-INSTRUCT paper.
Input: The content of the SELF-INSTRUCT paper.
Output: A concise summary of the paper's content.
</code></pre></div></div> <p>The objective of the SelfInstruct pipeline is to expand this dataset, emphasizing diversity. Importantly, this expansion does not involve generating new instructions. The instructions themselves remain unchanged. Instead, the focus is on expanding the associated input and output data for a given instruction, referred to as the <em>target instruction</em>. This process is called <em>instance generation</em>. It is worth mentioning that the instance generation process is carried out individually for each instruction, with each instruction serving as the <em>target instruction</em> in its respective round. Now, let us describe the steps of the SelfInstruct pipeline in details:</p> <ol> <li> <strong>Initialization with Human-Written Instructions:</strong> The first step involves initializing a <em>task pool</em> with a set of seed human-written instructions. In this case, they collect 175 human-written instructions, each corresponding to a specific task. This task pool serves as the starting point for generating a more extensive set of instructions. From this task pool, they sample 8 instructions for each <strong>iteration</strong>. Out of these 8 instructions, 6 are randomly selected from the original 175 human-written instructions (seed instructions), and the remaining 2 are sampled from model-generated instructions that were created in previous iterations.</li> <li> <strong>Instance Generation:</strong> The second step of the pipeline involves instance generation, where they create input-output pairs for the instructions. In this step, they employ two different approaches: the <strong>Input-first Approach</strong> and the <strong>Output-first Approach</strong>. <ul> <li> <strong>Input-first Approach:</strong> As mentioned previously, in the instance generation step, the focus is on creating input-output pairs for a given target instruction. Accordingly, in the input-first approach, the goal is to generate instances for each instruction by first focusing on creating the input field based on the instruction. And then, the focus would be on creating the output field based on the instruction and the gerenated input. Here’s how it works: <ul> <li>The pretrained language model is prompted with an instruction, and it is asked to generate the input fields for a specific task based on that instruction.</li> <li>The model interprets the instruction to understand what the task is, determines what additional input information is required, generates this input information, and then produces the corresponding output for that task.</li> <li>Essentially, the model generates the input and output sequentially, with the input being generated first. However, it’s mentioned that this approach might lead to inputs that are biased toward one label, especially for classification tasks. That is why they proposed the next approach for the instance generation.</li> </ul> </li> <li> <strong>Output-first Approach:</strong> In contrast, the Output-first Approach is used primarily for classification tasks and is designed to address the issue of input bias. Here’s how it works: <ul> <li>For classification tasks, the model first generates the possible class labels for the task. These class labels represent the different categories or options that the output could belong to.</li> <li>Once the class labels are generated, the model then generates the input for the task, conditioning it on each of the class labels. This approach ensures that the input is not biased toward a single label, making it more suitable for classification-type tasks.</li> </ul> </li> </ul> </li> <li> <strong>Filtering and Quality Control:</strong> The generated instances–the target instruction and the generated input and output–are passed through a filtering step to ensure diversity and quality of the generated instances. A filtering criteria could the the similarity of the genereated instance and the existing instances. If the similarity score–which can be measured by different metrics, such as ROUGE-L, is above a specific threshold, then the generated instance is considered to have a very low quality and will be excluded from the final dataset.</li> </ol> <p>For evaluation, they use their generated dataset in order to finetune GPT-3, called <strong>GPT3<sub>selfIns</sub></strong>. Then, they use the SuperNaturalInstractions framework–which is a large collection of tasks and their textual instructions for measuring the performance of their model. <strong>GPT3<sub>selfIns</sub></strong> outperforms GPT-3 by a large margin. However, it is still comparable (or even slightly behind) InstructGPT model.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">Here are some more articles relevant to this one:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-27/">Paper Review - Week 27</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-25/">Paper Review - Week 25</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-13/">Paper Review - Week 13</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-10/">Paper Review - Week 10</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-36/">Paper Review - Week 36</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>