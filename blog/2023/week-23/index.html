<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review - Week 23 | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Top NLP Papers Published from June 05 to June 11 "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/blog/2023/week-23/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review - Week 23</h1> <p class="post-meta"> June 11, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/papers"> <i class="fa-solid fa-tag fa-sm"></i> papers</a>   <a href="/blog/category/weekly-review"> <i class="fa-solid fa-tag fa-sm"></i> weekly-review</a>   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"> <a href="#palr-personalization-aware-llms-for-recommendation">PALR: Personalization Aware LLMs for Recommendation</a> <ul> <li class="toc-entry toc-h3"><a href="#introduction">Introduction</a></li> <li class="toc-entry toc-h3"><a href="#research-gap">Research Gap</a></li> <li class="toc-entry toc-h3"><a href="#solution-palr">Solution: PALR</a></li> <li class="toc-entry toc-h3"><a href="#experiments">Experiments</a></li> <li class="toc-entry toc-h3"><a href="#conclusion">Conclusion</a></li> </ul> </li> </ul> </div> <hr> <div id="markdown-content"> <p>Here is the list of the most interesting papers published in this week:</p> <ul> <li><a href="/blog/2023/week-23/#palr-personalization-aware-llms-for-recommendation">PALR: Personalization Aware LLMs for Recommendation</a></li> </ul> <hr> <h2 id="palr-personalization-aware-llms-for-recommendation"><a href="https://arxiv.org/pdf/2302.04237.pdf" rel="external nofollow noopener" target="_blank">PALR: Personalization Aware LLMs for Recommendation</a></h2> <h3 id="introduction">Introduction</h3> <p>his paper introduces a novel framework, PALR (Personalization Aware LLM for Recommendation), designed to integrate user historical behaviors with LLMs for more personalized and accurate item recommendations. Recognizing the challenges of incomplete knowledge representation and the limitations posed by extensive item pools, PALR addresses these issues through a multi-step approach, incorporating user profile summarization, candidate retrieval, and LLM-based recommendation generation. By fine-tuning the LLaMa 7B model and employing instruction-based techniques, PALR demonstrates its potential to enhance the reasoning capabilities of LLMs and provide more precise and relevant recommendations in various sequential recommendation tasks.</p> <h3 id="research-gap">Research Gap</h3> <p>The primary focus of the authors is to develop a personalized recommendation system leveraging LLMs while addressing the specific challenges commonly associated with such systems. The challenges which are the main focus of PALR are:</p> <ul> <li> <strong>Newly-added Items:</strong> The concern here is that newly added items to the recommendation system might not be represented in the LLM’s knowledge. This can result in the system being unable to make accurate recommendations for these newly-added items.</li> <li> <strong>Incomplete or Hallucinatory Results:</strong> LLMs can sometimes generate incomplete or even imaginary results, commonly referred to as the hallucination problem. This issue can lead to the inclusion of irrelevant or nonsensical recommendations, which undermines the trust and credibility of the recommendation system.</li> <li> <strong>Token Limitations:</strong> LLMs typically have restrictions on the number of tokens that can be included in their inputs. This token limitation can be a challenge, especially in the context of recommendation systems where the item pool may be extensive.</li> </ul> <h3 id="solution-palr">Solution: PALR</h3> <p>The main architecture of PALR is as follows: </p> <ul> <li> <strong>User Profile Summarization (using LLMs):</strong> The initial step involves feeding the user’s interaction history into an LLM to generate a summary of the user profile. This step aims to capture the user’s preferences and interests, which are then used to guide the recommendation process. By producing a concise representation of the user’s preferences, the system can better understand the user’s needs and tailor the recommendations accordingly.</li> <li> <strong>Retrieval System for Filtering Items:</strong> The retrieval system receives information about the user’s target task and their profile. It then filters the item pool to remove or filter out irrelevant items. As far as I know, the specific metrics used for filtering the items are explicitly mentioned in the paper, but they are likely based on relevance to the user’s preferences, historical interactions, or task-specific criteria. This step is crucial for managing the inclusion of newly-added items in the recommendation system and ensuring that the recommendations remain relevant and up-to-date.</li> <li> <strong>LLM-based Recommendation Generation:</strong> Then, another LLM is employed to generate the final recommendations based on a designed prompt. The designed prompt is created using the summarized user profile and the retrieved items. To be more specific, the designed prompt includes a task instruction, an output template, the summarized user profile, the user interaction history, and the retrieved items as candidate items for recommendations. By utilizing this LLM for recommendation generation, the framework leverages the model’s reasoning capabilities to provide accurate and personalized recommendations to the users.</li> </ul> <p>The following figure is an overview of the architecture:</p> <p style="text-align:center;"><img src="/assets/img/weekly-review/palr_architecture.png" alt="The Architecture" width="400" height="500"></p> <p>Also, here is a sample of prompts used for extracting user profile summary and recommendation items according to the user profiles.</p> <p style="text-align:center;"><img src="/assets/img/weekly-review/palr_prompt.png" alt="The Architecture" width="750" height="250"></p> <p><strong>Personal Comment:</strong> It is not clear if the LLM used in the user profile summerization and the one used in recommendation generation are two distinct LLMs or are the same. However, the authors mention that for the recommendation generation step, they leveraged LLaMa 7B model.</p> <p>Another important point is that the authors mention that fine-tuning the model has a significant effect in personalising the recommendation system. Specifically, they fine-tune the LLaMa 7B model to better adapt it for the recommendation scenario. The fine-tuning process involves incorporating instruction-based fine-tuning techniques. The fine-tuning process is as follows:</p> <ul> <li> <strong>Instruction Tasks:</strong> The authors create two types of instruction tasks, namely <em>Recommend</em> and <em>Recommend_Retrieval</em>, to guide the fine-tuning process. These tasks involve providing the model with specific instructions on generating recommendations based on a user’s historical interactions and the candidate items for recommendation.</li> <li> <strong>Retrieval Layer Agnostic:</strong> The fine-tuning process is not dependent on any specific retrieval layer within their framework. Despite training the model to select items from a list of candidates, the construction of this list during the fine-tuning process is not tied to the retrieval layer, ensuring the flexibility and adaptability of the framework.</li> </ul> <h3 id="experiments">Experiments</h3> <p>The primary aspects of the experimental setups are as follows:</p> <ul> <li> <strong>Datasets:</strong> The experiments were conducted on: (1) MovieLens-1M dataset, which contains 1 million ratings from 6000 users for 4000 movies; and (2) Amazon Beauty dataset, which is a real-world dataset from Amazon containing user-item interactions on beauty products.</li> <li> <strong>Baselines:</strong> The authors compare PALR with several baselines including: BPR-MF (Bayesian Personalized Ranking with Matrix Factorization), NCF (Neural Collaborative Filtering), GRU4Rec, Caser, and SASRec.</li> <li> <strong>Evaluation Metrics:</strong> The evaluation metrics used in the experiments are HR and NDCG.</li> <li> <strong>Results:</strong> The results indicate that the PALR framework outperforms the various baseline models by a substantial margin on both the Amazon Beauty and Movielens-1M datasets. The comparisons highlight the significance of incorporating a retrieval module and fine-tuning process in the PALR framework, leading to more accurate and relevant recommendations.</li> </ul> <h3 id="conclusion">Conclusion</h3> <p>In conclusion, this paper presents PALR as a promising framework that effectively combines the power of large language models with user historical behaviors to improve the accuracy and personalization of recommendation systems. By addressing the challenges of incomplete knowledge representation and token limitations within LLMs, PALR demonstrates its robustness and effectiveness in generating more relevant and contextually accurate recommendations for users.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">Here are some more articles relevant to this one:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-25/">Paper Review - Week 25</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-27/">Paper Review - Week 27</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-46/">Paper Review - Week 46</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-41/">Paper Review - Week 41</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/selective-fairness-in-recommenders/">Selective Fairness in Recommendation via Prompts</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>