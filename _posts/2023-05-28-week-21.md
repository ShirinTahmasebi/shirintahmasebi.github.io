---
layout: post
title: Paper Review - Week 21
thumbnail: /assets/img/weekly-review/nlp_cover_week_21.jpg
categories: [papers, weekly-review, nlp]
description: >
    Top NLP Papers Published from May 22 to May 28
toc:
  beginning: true
---

Here is the list of the most interesting papers published in this week:
* Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models
* Leveraging Large Language Models in Conversational Recommender Systems
* [SelfInstruct: Aligning Language Models with Self-Generated Instructions][selfInstructSum]

---

## [SelfInstruct: Aligning Language Models with Self-Generated Instructions][selfInstructPaper]

SelfInstruct focuses on the automatic generation of instruction instances for training language models to follow instructions effectively. The paper introduces a pipeline for generating instructions and associated input-output samples.


Before we dive into the step-by-step details of the pipeline, let's start by giving a broad overview of what this pipeline accomplishes overall. First of all, the dataset of instructions that is going to be generated and expanded in this work has three main attributes:

1. **Instruction:** This is the natural language instruction that defines a specific task. It provides the context for the task that the language model needs to understand and follow.
1. **Input:** This represents the input data or information required to perform the task described in the instruction. It can vary depending on the nature of the task and may include text, numbers, or other data.
1. **Output:** This corresponds to the expected output or the desired result of the task.

````
Example:

Instruction: Write a summary of the SELF-INSTRUCT paper.
Input: The content of the SELF-INSTRUCT paper.
Output: A concise summary of the paper's content.
````

The objective of the SelfInstruct pipeline is to expand this dataset, emphasizing diversity. Importantly, this expansion does not involve generating new instructions. The instructions themselves remain unchanged. Instead, the focus is on expanding the associated input and output data for a given instruction, referred to as the _target instruction_. This process is called _instance generation_. It is worth mentioning that the instance generation process is carried out individually for each instruction, with each instruction serving as the _target instruction_ in its respective round. Now, let us describe the steps of the SelfInstruct pipeline in details:

1. **Initialization with Human-Written Instructions:** The first step involves initializing a _task pool_ with a set of seed human-written instructions. In this case, they collect 175 human-written instructions, each corresponding to a specific task. This task pool serves as the starting point for generating a more extensive set of instructions. From this task pool, they sample 8 instructions for each **iteration**. Out of these 8 instructions, 6 are randomly selected from the original 175 human-written instructions (seed instructions), and the remaining 2 are sampled from model-generated instructions that were created in previous iterations.
1. **Instance Generation:** The second step of the pipeline involves instance generation, where they create input-output pairs for the instructions. In this step, they employ two different approaches: the **Input-first Approach** and the **Output-first Approach**.
  * **Input-first Approach:** As mentioned previously, in the instance generation step, the focus is on creating input-output pairs for a given target instruction. Accordingly, in the input-first approach, the goal is to generate instances for each instruction by first focusing on creating the input field based on the instruction. And then, the focus would be on creating the output field based on the instruction and the gerenated input. Here's how it works:
        - The pretrained language model is prompted with an instruction, and it is asked to generate the input fields for a specific task based on that instruction.
        - The model interprets the instruction to understand what the task is, determines what additional input information is required, generates this input information, and then produces the corresponding output for that task.
        - Essentially, the model generates the input and output sequentially, with the input being generated first. 
    However, it's mentioned that this approach might lead to inputs that are biased toward one label, especially for classification tasks. That is why they proposed the next approach for the instance generation.
  * **Output-first Approach:** In contrast, the Output-first Approach is used primarily for classification tasks and is designed to address the issue of input bias. Here's how it works:
       * For classification tasks, the model first generates the possible class labels for the task. These class labels represent the different categories or options that the output could belong to.
       * Once the class labels are generated, the model then generates the input for the task, conditioning it on each of the class labels.
    This approach ensures that the input is not biased toward a single label, making it more suitable for classification-type tasks.
1. **Filtering and Quality Control:** The generated instances--the target instruction and the generated input and output--are passed through a filtering step to ensure diversity and quality of the generated instances. A filtering criteria could the the similarity of the genereated instance and the existing instances. If the similarity score--which can be measured by different metrics, such as ROUGE-L, is above a specific threshold, then the generated instance is considered to have a very low quality and will be excluded from the final dataset.


For evaluation, they use their generated dataset in order to finetune GPT-3, called **GPT3<sub>selfIns</sub>**. Then, they use the SuperNaturalInstractions framework--which is a large collection of tasks and their textual instructions for measuring the performance of their model. **GPT3<sub>selfIns</sub>** outperforms GPT-3 by a large margin. However, it is still comparable (or even slightly behind) InstructGPT model.

[selfInstructPaper]: https://arxiv.org/pdf/2212.10560.pdf
[selfInstructSum]: /blog/2023/week-21/#selfinstruct-aligning-language-models-with-self-generated-instructions