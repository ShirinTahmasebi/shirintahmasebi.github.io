<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review - Week 20 | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Top NLP Papers Published from May 15 to May 21 "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/blog/2023/week-20/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/background/">Background </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review - Week 20</h1> <p class="post-meta"> May 21, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/papers"> <i class="fa-solid fa-tag fa-sm"></i> papers</a>   <a href="/blog/category/weekly-review"> <i class="fa-solid fa-tag fa-sm"></i> weekly-review</a>   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"> <a href="#up5-unbiased-foundation-model-for-fairness-aware-recommendation">UP5: Unbiased Foundation Model for Fairness-aware Recommendation</a> <ul> <li class="toc-entry toc-h3"><a href="#exploring-bias-in-llm-based-rs">Exploring Bias in LLM-based RS</a></li> <li class="toc-entry toc-h3"><a href="#solution-conterfactually-fair-prompting">Solution: Conterfactually-fair Prompting</a></li> </ul> </li> </ul> </div> <hr> <div id="markdown-content"> <p>Here is the list of the most interesting papers published in this week:</p> <ul> <li><a href="/blog/2023/week-20/#up5-unbiased-foundation-model-for-fairness-aware-recommendation">UP5: Unbiased Foundation Model for Fairness-aware Recommendation</a></li> <li>Towards Expert-Level Medical Question Answering with Large Language Models</li> <li>StructGPT: A General Framework for Large Language Model to Reason over Structured Data</li> </ul> <hr> <h2 id="up5-unbiased-foundation-model-for-fairness-aware-recommendation"><a href="https://arxiv.org/abs/2305.12090" rel="external nofollow noopener" target="_blank">UP5: Unbiased Foundation Model for Fairness-aware Recommendation</a></h2> <p>Fairness in Recommendation Systems (RS) is one of the interesting and widely-discussed topics. The primary objective of such research is to ensure that users are not subjected to discrimantion based on their sensitive attributes, such as gender, age, or race. Apart from that, while it is important to mitigate bias in RSs and make recommendations independent of the users’ sensitive attributes, it is equally important to still offer personalized and relevant recommendations for users. So, the challange lies in making a balance between mitigating bias in RSs and generating accurate and tailored recommendations.</p> <p>This paper explores language-model-based RSs. The benefit of using language models as the backbone of RSs is that it would be more able to capture contextual dependencies. So, the main requirements taken into account in this work are:</p> <ol> <li> <p>Allowing users to mark certain attributes as sensitive, based on which they do not wish to be discriminated. The reason for having such requirement is that, for instance, in a movie RS, users may be interested on recieving the recommendations tailored to their age or race.</p> </li> <li> <p>Developing a unified model capable of handling bias mitigation across all sensitive attributes. In other words, rather than relying on separate models for each attribute, a more scalable approach is having a single model that handles all of them.</p> </li> <li> <p>Ensuring that having fairness in RSs would not lead to a significant decrease in the recommender’s performance.</p> </li> </ol> <p>In this paper, the authors first propose several approaches for measuring bias in RSs. Then, they propose a novel prompting approach for mitigating bias in the recommenders. Finally, they describe their idea for considering several sensitive attributes in bias mitigation.</p> <h3 id="exploring-bias-in-llm-based-rs">Exploring Bias in LLM-based RS</h3> <p>In this section, we will review the proposed approaches for measuring bias in LLM-based RSs. Before describing these approaches, let us define what fair recommendation means in a formal notation. RS is considered to be fair if for any possible user \(u\) with features \(X = x\) and having sensitive attributes \(K = k\), the following equation is satistied for top-N recommended items–denoted by L:</p> \[P( L_k | X= x, K=k) = P(L_{k^{'}} | X = x, K = k^{'})\] <p>Now, let us review the three bias exploration approaches:</p> <ol> <li> <p>Manually-Designed Prompt: In this approach mannually crafted discrete prompts are used for querying the RS: <code class="language-plaintext highlighter-rouge">What is the {attribute} of user_{user_id}? Output: {user attribute value}</code>. Also, another similar approach would be to include user-item interaction history in the prompt design: <code class="language-plaintext highlighter-rouge">User_{user_id} has watched moviews {sequence of movie ids}. What is the {attribute} of user_{user_id}? Output: {user attribute value}</code>.<br> They have used these prompts–a separate prompt template for each of the gender, age, occupation and marital status attributes–on a specific language model (probabely, P5) and reported the AUC of the predicted attributes as the results. Since in both prompting approaches and for all of the mentioned attributes, the AUC is either 50\% or slightly above 50\%, they concluded that this approach is not a promising one for capturing bias in RSs.</p> </li> <li> <p>Soft-probing Prompt-tuning: In this approach, the authors leveraged and encoder-decoder-based architecture. They assigned two soft prompts to each of the sensitive attributes: one for the encoder part and the other for the decoder part. The encoder and decoder soft prompts are calculated using a 2-layer and 5-layer MLPs, respectively. The loss function used for training these two MLPs will be explained later. Apart from the two mentioned soft prompts, they defined a discrete prompt, describing users and their interactions as <code class="language-plaintext highlighter-rouge">User user_{id} has watched movies {squence of item ids}</code>.<br> Then, for creating input to the encoder and the decoder components, they employed these formats: <code class="language-plaintext highlighter-rouge">Encoder: The Encoder Soft Prompt of the Attribute + Discrete Prompt for User {user_id}</code> and <code class="language-plaintext highlighter-rouge">Decoder: The Decoder Soft Prompt of the Attribute + Encoder Output</code>. <br> Accordingly, the output of the decoder is used for tuning the soft-prompts by training the two MLPs using the negative log-likelihood of the attribute value as the loss function.<br> The results of this approach revealed that the recommendation systems consider the users’ personal and sensitive attributes for recommending items to users.</p> </li> <li> <p>Multi-class Classifier: In this approach, a language model is fed by a discrete prompt describing the user information. Then, the encoder-generated embeddings for the user tokens are passed to a 7-layer MLP as the attribute classifier. The classifier is trained based on the cross-entropy loss function. In this approach, there is a separate classifier per sensitive attribute. Finally, AUC is reported to measure how well the classifier predicts the user attributes. The results proved that the classifier is the best in capturing fairness and bias.</p> </li> </ol> <h3 id="solution-conterfactually-fair-prompting">Solution: Conterfactually-fair Prompting</h3> <p>They proposed a novel and creative prompting-based solution for mitigating bias. Their solution uses the adversarial learning concepts for optimizing the prompts. More specificly, the steps of their solution are as follows:</p> <ol> <li> <p>Two soft prompts are assigned to each sensitive attribute, named \(p_{enc}\) for the encoder section and \(p_{dec}\) for the decoder section. The main objective of the whole solution would be to optimize all of the soft prompts.</p> </li> <li> <p>The encoder is then fed by the input \(x\) which is concatenated to \(p_{enc}\)–in case of considering only a single sensitive attribute: \(hidden\_states = Encoder(p_{enc}, x)\)</p> </li> <li> <p>Then, the output of the encoder and \(p_{dec}\) is passed to the decoder to generate output \(y\): \(y = Decoder(p_{dec}, hidden\_states)\)</p> </li> <li> <p>The output of the decoder can be represented by: \(p_{\theta_{dec}}(y_j | p_{dec}, y_{0:j-1},hidden\_states)\)</p> </li> <li> <p>Now, to use the adversarial learning approach, the adversary uses the module in the multi-class classifier–denoted by \(C\)–as the discriminator module. The adversary tries to correctly classfiy user attirbutes. Then, the goal of the whole system is to avoid the advarsay to classify the attributes correctly. Accordingly, to optimize the soft prompts, two loss functions are defined: \(L_{rec}\)–the recommender loss, which should be minimized–and \(L_{dis}\)–the adversarial classification loss, which should be maximized. \(L_{rec}\) is defined as the negative log likelihood loss of the decoder output and \(L_{dis}\) is defined as the Cross-Entropy Loss (CEL) for classification (\(c_u\) is the correct attribute value for the user \(u\)): \(L_{rec} = \Sigma_{j=1}^{|y|} log P(y_{j} | p_{dec}, y_{0:j-1}, hidden\_states)\) \(L_{dis}^{k} = CEL(c_u|C(mean(hidden\_states[i:j])))\)</p> </li> <li> <p>Considering \(\lambda_{k}\) as the discriminator weight for attribute \(k\), the whole loss value for the attribute \(k\) is: \(L_k = \Sigma_{u} L_{rec} - \lambda_{k}.L_{k}^{dis}\)</p> </li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">Here are some more articles relevant to this one:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-25/">Paper Review - Week 25</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-9/">Paper Review - Week 9</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/selective-fairness-in-recommenders/">Selective Fairness in Recommendation via Prompts</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-27/">Paper Review - Week 27</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-50/">Paper Review - Week 50</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>