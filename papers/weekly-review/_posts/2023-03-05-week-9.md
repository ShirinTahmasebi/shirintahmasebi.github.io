---
layout: post
title: Paper Review - Week 9
image: 
  path: /assets/img/weekly-review/nlp_cover_week_09.jpg
categories: [papers, weekly-review, nlp]
description: >
    Top NLP Papers Published from February 27 to March 05
sitemap: false
hide_last_modified: true
---

To me, the most interesting papers among those published in this week are:
* [MathPrompter: Mathematical Reasoning Using Large Langugage Models][mathPrompter]
* [LLaMA: Open and Efficient Foundation Language Models][LLaMa]


## MathPrompter

This paper focuses on using LLMs for mathematical reasoning. Some of the challenges in this work are as follows:

* Mathematical operations usually have a single correct answer.
* Not only the final output is important, the procedure and the intermidate steps that resulted into that final output should also be correct.
* It is difficult to ensure that the generated output and the intermediate steps are all correct. In other words, it is better to have a metric to show that how much the model is confident about the generated output!

Accordingly, MathPrompter tries to propose a solution to increase the validity and reliability of mathematical reasoning using LLMs. Their solution is to simulate the usual approach that studnets usually take for solving a math problem. So, the steps in MathPrompter is as follows:

1. Receiving the definition of a mathematical problem as text. For example:
````
At a restaurant, each adult meal costs $5 and kids eat free. If a group of 15 people came in and 8 were kids, how much would it cost for the group to eat? 
````
1. Generating a template for the input question and creating a list of values for solving the template:
````
Template = At a restaurant, each adult meal costs A and kids eat free. if a group of B people came in and C were kids, how much would it cost for the group to eat?
Mapping = {A:5, B:15, C:8}
````
1. Creaing proper prompts for creating different solutions. For example, one solution can be a python function and the other can be a algebraic equation. So, by providing these prompts to the LLM:
````
Algebraic prompt: Write a mathematical equation and generate the answer format starting with ‘Answer =’
Python prompt: Write a Python function that returns the answer.
````
then, the LLM is supposed to generated the two following outputs:
````python
# Algebraic expression output
Answer = A * (B - C)
# Python expression output
def total_price(A, B, C):
  return A * (B - C)
````
These outputs can help the user to have an insight about how the LLM is reasoning.
1. Then, MathPrompter uses different randomized values for $$A$$, $$B$$, and $$C$$. Then, it passes all the randomized values to the both outpus. If, for more than 5 times, the result of the two outputs (algebraic and python expression) are the same, then both of them are accepted as the correct solutions for the mathematical problem.

This is definitely a very interesting and novel idea. However, I personally have some concerns about it:
1. First of all, MathPrompter is not making it easier for LLMs to find a solution. The only thing that it does is to ask LLMs to generate multiple outputs, such as algebraic and python expression. 
1. MathPrompter uses several randomized values (at least 5 values) to validate if the LLM outputs result in the same number or not. However, it is not clear that how these randomized values are generated. If users are supposed to provide these values, then I think it somehow makes the LLM useless here! Because users need to solve the problem themselves to be able to provide such values. So, in this case, they don't need LLMs anymore! :)
1. If for the specific values in the input mathematical problem, algebraic and python expressions result in different values, then what can be reported to the user?


[mathPrompter]: https://arxiv.org/pdf/2303.05398.pdf
[LLaMa]: https://arxiv.org/pdf/2302.13971.pdf