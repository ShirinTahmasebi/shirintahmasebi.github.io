<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review - Week 22 | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Top NLP Papers Published from May 29 to June 04 "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/blog/2023/week-22/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/background/">Background </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review - Week 22</h1> <p class="post-meta"> June 04, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/papers"> <i class="fa-solid fa-tag fa-sm"></i> papers</a>   <a href="/blog/category/weekly-review"> <i class="fa-solid fa-tag fa-sm"></i> weekly-review</a>   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#black-box-adversarial-prompting-for-foundation-models">Black Box Adversarial Prompting for Foundation Models</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>Here is the list of the most interesting papers published in this week:</p> <ul> <li><a href="/blog/2023/week-22/#black-box-adversarial-promoting-for-foundation-models">Black Box Adversarial Primoting for Foundation Models</a></li> </ul> <hr> <h2 id="black-box-adversarial-prompting-for-foundation-models"><a href="https://arxiv.org/pdf/2302.04237.pdf" rel="external nofollow noopener" target="_blank">Black Box Adversarial Prompting for Foundation Models</a></h2> <p>Before summarizing this paper, I need to explain some of the concepts used frequently in the paper and categorize them: <em>adversarial examples</em>, <em>adversarial attack</em>, <em>gradiant-based approaches</em>, and <em>square attack</em>.</p> <ul> <li> <p><strong>Adversarial Example:</strong> An adversarial example is a sample of data that has been intentionally designed to mislead a machine learning model to make mistakes in its predictions. These examples are created by applying small, often imperceptible, perturbations to the original input data. For example, let us say that we have a language model for sentiment analysis of the input sentences. Then, assume that the original sentence is: <em>I love this product. It is amazing</em>. Then, an adversarial sentence would be: <em>I love this product. It is terrible</em>. So, as you see the adversarial sentence is quite ambiguous and it can be interpreted in multiple ways. But the question is that how generating such examples can be beneficial for the model? To answer this question, I would like to highlight the fact that the purpose of the adversarial examples is not to help the model to learn better. The main purpose is to help the model to be exposed to its vulnerabilities and limitations. For example, here, the adversary example is creafte in a way that introduces ambiguity and uncertainty.</p> </li> <li> <p><strong>Adversarial Attacks:</strong> Adversarial attacks are a set of techniques that are used for generating adversarial examples. Adversarial attacks encompass various methods and strategies aimed at making perturbations or modifications to the input data to create adversarial examples that can deceive or mislead machine learning models. <br> The goal of adversarial attacks is to expose vulnerabilities in machine learning models, understand their weaknesses, and evaluate their robustness against potential threats. By generating adversarial examples, researchers can assess how well a model performs in the presence of perturbations that are designed to mislead it.</p> </li> <li> <p><strong>How adversarial attacks can be used to optimize an objective fuction?</strong> Let us talk about it in a more detailed way. Let us say that we want to find a prompt that can maximize the performance of a language model on a specific downstream task. Then, first we initialize a prompt and measure how well the model performs using that prompt. So, after that, we can generate a new prompt from the previous one using one of the adversarial attacks. Then, leveraging the performance of the languge model using the new prompt, we can decide which prompt we can use. for example, we can update a prompt using the genetic algorithm which is an evolutionary optimization algorithm that can be considered as a type of adversarial attack for generating adversary examples.<br> This process continues until we can find a prompt which leads to an optimized performance–minimized loss value.</p> </li> <li> <p><strong>Adversarial Training:</strong> In adversarial training, the main focus is to control the training process. So, in adversarial training, the objective function is often a combination of the adversarial loss and the regular loss, and the main goal is to minimize the regular loss while simultaneously maximizing the adversarial loss.</p> </li> <li> <p><strong>What is the difference between adversarial training and adversarial attack?</strong> Adversarial training modifies the objective function during the model’s training phase. The objective function includes both the regular loss (e.g., cross-entropy loss) and the adversarial loss. One the other hand adversarial attack does not modify the model’s training objective function. Instead, it aims to generate specific adversarial examples that can mislead the model after it has been trained. <br> In better words, adversarial training is a defense mechanism applied during model training to improve its resilience against adversarial examples. It alters the objective function to encourage the model to make correct predictions on both clean and adversarial data. On the other hand, adversarial attack does not modify the model’s training process but instead focuses on finding specific inputs that can deceive the model after training, highlighting areas of vulnerability in the model’s decision-making process. <br> The <a href="/blog/2023/week-20/#up5-unbiased-foundation-model-for-fairness-aware-recommendation">UP5 Paper</a> uses adversarial training technique. But, <a href="https://arxiv.org/pdf/2302.04237.pdf" rel="external nofollow noopener" target="_blank">this paper</a> leverages adversarial attack techniques.</p> </li> <li> <p><strong>Square Attack:</strong> It is a type of adversarial <strong>attack</strong> which can also be applied in NLP domain. Let us say that we want to optimzize a soft prompt using the square attack technique. The steps are as follows:</p> <ul> <li> <p>Subset Selection: Among all the tokens in the soft prompt, we candidate a set of them (e.g., \(k\) tokens) for being replaced with other tokens. To replace them, we need to keep the indices of the candidation to-be-replaced tokens.</p> </li> <li> <p>Sampling Values: To replace the \(k\) tokens, we need to generate \(k\) random vectors of the same size. Accordingly, we can generate \(k\) modified prompts, \(p_{i}\) for \(i = 0 .. k\). For example, \(p_i\) represents a new modifiend prompt where the token \(i\) is replaced with a generated random vector of the same size.</p> </li> <li> <p>Update Prompt: Let us say that, for prompt \(p_{i}\) where \(i = 0 .. k\), the objective function is represented by \(f(p_{i})\). Then, the prompt \(p_j\) for which \(f(p_{i})\) is the best one is chosen as the updated prompt.</p> </li> </ul> </li> </ul> <p>So, after providing such background information, it is much easier and more straightforward to explain this paper. This paper focuses on using adversarial attack techniques for optimizing soft prompts in order to improve the performace of the foundation models. The main objective of this paper is that their solution should be independent of the model architecture. So, in this case, it only views the foundation models as a black-box and can be adapted to other foundation models with different architectures.</p> <p>The authors proposed their solution for both language models and vision models. But, since I am more familiar with the language models rather than vision models, I only explain the language-model-related part of the paper.</p> <p>The process of the soft prompt optimization in this paper has the following stages:</p> <ol> <li>Initializing a random candidate word embedding as the discrete and hard prompt</li> <li>Project the hard prompt to another token embedding space to have soft prompts</li> <li>Using the adversarial attack techniques–more specifically, the square attack technique–to generate several adversary prompts</li> <li>Convert the generated soft prompts to the hard prompt–hard prompts which are the closest and the most similar ones to the soft ones.</li> <li>Calculating the language model loss for the newly-generated hard prompts</li> <li>Select the prompt which results the best performance</li> <li>Repeat steps 2 to 7 for the newly-selected prompt</li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">Here are some more articles relevant to this one:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-9/">Paper Review - Week 9</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/week-12/">Paper Review - Week 12</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-27/">Paper Review - Week 27</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-10/">Paper Review - Week 10</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/week-21/">Paper Review - Week 21</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>