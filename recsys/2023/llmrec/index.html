<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LLMRec | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Benchmarking Large Language Models on Recommendation Task "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/recsys/2023/llmrec/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CV </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">Publications</a> <a class="dropdown-item " href="/background/">Background</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Notes </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/bias/">Bias</a> <a class="dropdown-item " href="/tokenization/">Tokenization</a> <a class="dropdown-item " href="/llm_judge/">LLM as Evaluator</a> <a class="dropdown-item " href="/prompt/">Prompt Engineering</a> <a class="dropdown-item " href="/compression/">LLM Compression</a> <a class="dropdown-item " href="/agents/">LLM Agents</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/recsys/">Recommendation Systems</a> <a class="dropdown-item " href="/other/">Others</a> </div> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">LLMRec</h1> <p class="post-meta"> August 27, 2023 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2023   ·   <i class="fa-solid fa-hashtag fa-sm"></i> llm   <i class="fa-solid fa-hashtag fa-sm"></i> recsys   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"> <a href="#llmrec-benchmarking-large-language-models-on-recommendation-task">LLMRec: Benchmarking Large Language Models on Recommendation Task</a> <ul> <li class="toc-entry toc-h3"><a href="#introduction">Introduction</a></li> <li class="toc-entry toc-h3"><a href="#solution-llmrec">Solution: LLMRec</a></li> <li class="toc-entry toc-h3"><a href="#experiments">Experiments</a></li> <li class="toc-entry toc-h3"><a href="#conclusion">Conclusion</a></li> </ul> </li> </ul> </div> <hr> <div id="markdown-content"> <h2 id="llmrec-benchmarking-large-language-models-on-recommendation-task"><a href="https://arxiv.org/pdf/2308.12241.pdf" rel="external nofollow noopener" target="_blank">LLMRec: Benchmarking Large Language Models on Recommendation Task</a></h2> <h3 id="introduction">Introduction</h3> <p>Despite the developments in LLMs, the integration of LLMs into the domain of recommendation systems has not been thoroughly explored. This research aims to bridge this gap by proposing LLMRec, an LLM-based recommender system crafted for benchmarking LLMs across various recommendation tasks.</p> <h3 id="solution-llmrec">Solution: LLMRec</h3> <p>The key steps involved in the LLMRec system are:</p> <ul> <li> <strong>Prompt Generation:</strong> Creating task-specific prompts using modules like task description, behavior injection, and format indicator modules. It seems to utilize template-based prompts for the different recommendation tasks, and it doesn’t explicitly mention an approach for optimizing the prompts themselves.</li> <li> <strong>Model Processing:</strong> Passing the created prompts to the LLMs, with the option of fine-tuning the models when necessary.</li> <li> <strong>Output Refinement:</strong> Evaluating the results using the output refinement module, which checks and refines the output of the LLMs, particularly addressing any issues related to hallucination or non-compliance with the desired output format. It doesn’t explicitly mention specific guidelines for the output refinement module. However, the concept of the output refinement module implies the need for a mechanism that can check and correct the output of the LLMs, particularly when it comes to hallucinations or outputs that do not meet the desired format or quality.</li> <li> <strong>Evaluation:</strong> Comparing the performance of the LLMs with various benchmarks and baseline methods for different recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization.</li> </ul> <p>An overview of the architecture of LLMRec is depicted in the following figure:</p> <p style="text-align:center;"><img src="/assets/img/weekly-review/llmrec_benchmark_architecture.png" alt="The Architecture" width="850" height="500"></p> <h3 id="experiments">Experiments</h3> <p>The primary aspects of the experimental setup are outlined below:</p> <ul> <li> <strong>Benchmarks:</strong> The benchmarks include various recommendation tasks, such as rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. The system evaluates the performance of off-the-shelf LLMs, including ChatGPT, ChatGLM, LLaMA, and Alpaca, and compares their results with state-of-the-art methods and baseline models for each specific recommendation task.</li> <li> <strong>Datasets:</strong> The study primarily focuses on evaluating the Beauty category within the Amazon dataset, which comprises customer review text and associated metadata for products.</li> <li> <strong>Evaluation Metric:</strong> For <strong>rating prediction</strong>, the evaluation metrics used are Root Mean Square Error (RMSE) and Mean Absolute Error (MAE). For <strong>sequential and direct recommendation tasks</strong>, the evaluation metrics include HR and NDCG. For <strong>explanation generation and review summarization</strong>, the evaluation metrics involve BLEU and ROUGE.</li> </ul> <h3 id="conclusion">Conclusion</h3> <p>In conclusion, this study has shed light on the potential of LLMs in the field of recommendation systems. Through the development and evaluation of the LLMRec system, they have demonstrated that LLMs, while exhibiting limited proficiency in certain accuracy-based tasks, showcase significant promise in explainability-based tasks.</p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>