<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review - Week 33 | Shirin Tahmasebi </title> <meta name="author" content="Shirin Tahmasebi"> <meta name="description" content="Top NLP Papers Published from August 14 to August 20 "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?ce48ee9bc248ee6b18f3aeefc03ed2f9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shirintahmasebi.github.io/other/2023/week-33/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shirin Tahmasebi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CV </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">Publications</a> <a class="dropdown-item " href="/background/">Background</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Notes </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/bias/">Bias</a> <a class="dropdown-item " href="/tokenization/">Tokenization</a> <a class="dropdown-item " href="/llm_judge/">LLM as Evaluator</a> <a class="dropdown-item " href="/prompt/">Prompt Engineering</a> <a class="dropdown-item " href="/compression/">LLM Compression</a> <a class="dropdown-item " href="/agents/">LLM Agents</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/recsys/">Recommendation Systems</a> <a class="dropdown-item " href="/other/">Others</a> </div> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review - Week 33</h1> <p class="post-meta"> August 20, 2023 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2023   ·   <i class="fa-solid fa-tag fa-sm"></i> papers   <i class="fa-solid fa-tag fa-sm"></i> weekly-review   <i class="fa-solid fa-tag fa-sm"></i> nlp   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#llm-rec-personalized-recommendation-via-prompting-large-language-models">LLM-Rec: Personalized Recommendation via Prompting Large Language Models</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>Here is the list of the most interesting papers published in this week:</p> <ul> <li><a href="/blog/2023/week-33/#llm-rec-personalized-recommendation-via-prompting-large-language-models">LLM-Rec: Personalized Recommendation via Prompting Large Language Models</a></li> </ul> <hr> <h2 id="llm-rec-personalized-recommendation-via-prompting-large-language-models"><a href="https://arxiv.org/pdf/2307.15780.pdf" rel="external nofollow noopener" target="_blank">LLM-Rec: Personalized Recommendation via Prompting Large Language Models</a></h2> <p>The main focus of this paper is to explore the impact of using various prompting approaches on improving the quality in recommendation systems. Let us consider having a recommendation system which receives both item embedding and user embedding as input and, as output, determines whether or not the item should be recommended to the user.</p> <p>The core architecture of LLM-Rec is a two-layer Multi-Layer Perception (MLP), which recieves the <strong>item description</strong> as input. We will delve into how item descriptions are generated shortly. By creating such item description and passing it to the MLP, the output of the last layer of MLP is considered as the final item embedding. The next step involves calculating the dot product between the final item embedding and the user ID embedding (it is not clear what is considered as the user ID embedding). This product is then passed through a Sigmoid function, producing the final relevance score between the user and the item. Notably, the Binary Cross Entropy Loss function is used for training the MLP model, treating each user-item interaction as a binary value.</p> <p>Now, let us focus on how the item descriptions are created. First of all, in some cases, as in the MovieLens benchmark, language models such as GPT-3 can be leveraged to obtain a more detailed description of items. For example, in the MovieLens benchmark, the GPT-3 model is instructed to give a summarization of each movie. Once the detailed item description is generated, various prompting approaches are employed to enrich the item descriptions. These prompting approaches are:</p> <ol> <li>Basic Prompting: The basic prompting approach can be divided into three different promptings. All these three approaches share the common characteristic of not providing additional information to the language model. <ul> <li>\(p_{para}\): The language model is instructed to paraphrase item descriptions. For example, the prompt can be: <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. Paraphrase it!</code>.</li> <li>\(p_{tag}\): The language model is instructed to paraphrase item descriptions using tags. For example, <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. Summarize it with tags.</code>.</li> <li>\(p_{infer}\): The language model is instructed to infer the charactristic of the provided item deescription. For instance, <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. What kind of emotions can it evoke?</code>.</li> </ul> </li> <li>Recommendation-driven Prompting: In this approach, a recommendation-driven instruction is added to the basic prompting approaches. Considering the type of the basic prompting being used, the recommendation-driven prompts can be represented by \(p^{rec}_{para}\), \(p^{rec}_{tag}\), and \(p^{rec}_{infer}\). <ul> <li>\(p^{rec}_{para}\): An example can be: <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. What else should I say if I want to recommend it to others?</code> </li> <li>\(p^{rec}_{tag}\): An example can be: <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. What tags should I use if I want to recommend it to other?</code> </li> <li>\(p^{rec}_{infer}\): An example can be: <code class="language-plaintext highlighter-rouge">The description of an item is as follows: {DESCRIPTION}. Recommend it to others with a focus on the emotions it can evoke.</code> </li> </ul> </li> <li>Engagement-guided Prompting: This type of prompting, denoted by \(p^{eng}\), is designed by taking the \(T\) most important neighbor items into account. In other words, first the \(T\) most important neighbor items are identified–the importance measuring metric is <strong>Personalized PageRank (PPR)</strong>. Let us assume that \(d_{target}\) represent the target item description (the item which we want to decide whether to recommend to a specific user or not), and \(d_1, d_2, ..., d_T\) denote the description of the \(T\) most similar neighbor items, then an example of this prompting approach can be: <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Summarize the commonalities among the following descriptions: $$d_{target}, d_1, d_2, ..., d_T$$
</code></pre></div> </div> </li> </ol> <p>For evaluating their apporach, they have used two datasets:</p> <ol> <li> <strong>MovieLens-1M</strong>, which contains user ratings to some movies. In MovieLens, the movie data only inlcudes its name and genre. However, LLM-Rec uses a more detailed information of movies. For providing such details, the movie name is passed to a language model–more specifically, GPT-3–which is asked to provide a summary of the movie. So, instead of only using the movie name and its genre as the input, a more detailed summary of the movie is used as input. The input of the GPT-3 model for asking it to summarize the movie is as follows: <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Summarize the movie [title] with one sentence. The answer cannot include the movie title.
</code></pre></div> </div> </li> <li> <strong>Recipe</strong>, which contains the details and review of different recipes extracted from Food.com. The details of each recipe contain ratings, reviews, recipe names, descriptions, ingredients.</li> </ol> <p>The evaluation metrics used for measuring the performance are:</p> <ul> <li> <strong>Precision@K</strong>: Precision measures the accuracy of the positive predictions made by a recommendation system.Precision@K evaluates the precision of the top \(K\) recommendations. It calculates the ratio of relevant items among the top \(K\) recommended items. Higher Precision@K indicates that a higher proportion of the recommended items are relevant to the user.</li> <li> <strong>Recall@K</strong>: Recall measures the ability of a recommendation system to find all relevant items. Recall@K evaluates the recall of the top \(K\) recommendations. It calculates the ratio of relevant items found among the top \(K\) recommendations. Higher Recall@K indicates that a higher proportion of all relevant items were included in the top \(K\) recommendations.</li> <li> <strong>NDCG@K</strong> (Normalized Discounted Cumulative Gain at \(K\)): NDCG is a metric that considers both the relevance of recommended items and their ranking. NDCG@K evaluates the quality of recommendations at a specific cutoff point \(K\). It assigns higher scores to highly relevant items that are ranked higher in the recommendation list. It takes into account the diminishing returns of relevance for items further down the list, normalizing the score between 0 and 1. Higher NDCG@K indicates better-ordered recommendations with more relevant items at the top of the list.</li> </ul> <p><strong>My Comments:</strong> This summary is for the second version of this paper, published in August 16. In this version, the results are presented in Table 2 and Figure 4. However, it is not clear that which prompting strategy is used for Table 2. According to the numbers in Table 2, LLM-Rec can outperform other baselines for both MovieLens and Recipe. However, Figure 4 reports performance per prompting strategy, and the numbers seem inconsistent with those in Table 2. According to Figure 4, LLM-Rec does not seem to outperform two of the baselines (AutoInt and DCN-V2) for Recipe. Furthermore, the improvement for MovieLens, as indicated in Figure 4, does not appear to be significant.</p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Shirin Tahmasebi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>